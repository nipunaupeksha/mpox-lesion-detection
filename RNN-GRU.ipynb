{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a3bec-c87b-4eb8-b861-70d46ea5eb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import keras_tuner as kt\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from keras_tuner import Hyperband\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, f1_score\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import GRU, Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, Reshape, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import cv2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb925042-d146-4fa0-a672-0f543586da16",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/images'\n",
    "RNN_IMAGE_RESULTS = './results/rnn/images'\n",
    "RNN_HISTORY_RESULTS = './results/rnn/history'\n",
    "RNN_REPORT_RESULTS = './results/rnn/reports'\n",
    "RNN_MODEL_RESULTS = './results/rnn/models'\n",
    "\n",
    "TRAIN_DIRECTORY = 'train'\n",
    "VALIDATION_DIRECTORY = 'val'\n",
    "TEST_DIRECTORY = 'test'\n",
    "\n",
    "SUB_DIRECTORIES = [TRAIN_DIRECTORY, TEST_DIRECTORY, VALIDATION_DIRECTORY]\n",
    "CATEGORY_DIRECTORIES = ['Chickenpox', 'Cowpox', 'Healthy', 'HFMD', 'Measles', 'Monkeypox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a6615b-a011-4a92-ac47-fc10f565f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images(dir_name):\n",
    "    for dataset_type in SUB_DIRECTORIES:\n",
    "        total = 0\n",
    "        dir_type = os.path.join(dir_name, dataset_type)\n",
    "        print(f\"============ {dataset_type} dataset ===========\")\n",
    "        for category in os.listdir(dir_type):\n",
    "            category_path = os.path.join(dir_type, category)\n",
    "            if not os.path.isdir(category_path):\n",
    "                continue\n",
    "            images = [img for img in os.listdir(category_path) if img.endswith(('jpg','jpeg'))]\n",
    "            print(f\"Number of images in {category_path.split('/')[-1]}: {len(images)}\")\n",
    "            total += len(images)\n",
    "        print(f\"Total image count: {total}\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9a1b5b-9cf8-4a79-b963-8198f463b005",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_images(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf83346-c3c0-4cfa-afbb-8d07696c6a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_to_df(base_path, dataset_type):\n",
    "    path = os.path.join(base_path, dataset_type)\n",
    "    image_dir = Path(path)\n",
    "\n",
    "    file_paths = list(image_dir.glob(r'**/*.jpg'))\n",
    "    labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], file_paths))\n",
    "\n",
    "    file_paths = pd.Series(file_paths, name='Path').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    image_df = pd.concat([file_paths, labels], axis=1)\n",
    "\n",
    "    samples = []\n",
    "    for record in image_df['Label'].unique():\n",
    "        samples.append(image_df[image_df['Label']==record])\n",
    "    image_df = pd.concat(samples, axis=0).sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    return image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6951a02-ebad-413f-a4fe-cb52bc272419",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load_images_to_df(DATA_PATH, TRAIN_DIRECTORY)\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e89fb05-df5d-4eb3-9c3b-7ff2d4188a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = load_images_to_df(DATA_PATH, VALIDATION_DIRECTORY)\n",
    "df_val.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1ef4b5-7c70-4e46-88cb-a8f83a8edcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = load_images_to_df(DATA_PATH, TEST_DIRECTORY)\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bfaa26-5612-494c-b1e6-75a2bcba4d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie_plot_from_df(df, title):\n",
    "    pie = df[\"Label\"].value_counts()\n",
    "    pie.plot(kind=\"pie\", autopct=\"%1.2f%%\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xlabel(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f13d5a8-6444-4569-9d65-1e9fb79de745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_from_df(df, nrows, ncols):\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15,8), subplot_kw={\"xticks\":[], \"yticks\":[]})\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(plt.imread(df.Path[i], -1))\n",
    "        ax.set_title(df.Label[i])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a4bf75-0cee-4828-bed0-445c8cc3f262",
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_plot_from_df(df_train, \"Image Percentages from Train Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f048abb7-3bf2-4240-bf71-728bd04d8aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_plot_from_df(df_val, \"Image Percentages from Val Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb281af-1ac7-4928-9f9d-d05f9484df45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_plot_from_df(df_test, \"Image Percentages from Test Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07992a52-d82d-4b75-82d9-97b95dacc423",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_from_df(df_train, 6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e11a52-40e4-49b8-ac66-77cf2b2790c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_from_df(df_val, 6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a350ee-e753-43e4-a78f-2298409fc5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_from_df(df_test, 6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639042ea-38fe-4f2b-8933-1307c2b8e6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(df):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for index, row in df.iterrows():\n",
    "        img = tf.keras.utils.load_img(row['Path'], target_size=(224, 224))\n",
    "        img_array = tf.keras.utils.img_to_array(img)/255.0\n",
    "        img_array = img_array.reshape(224, -1)\n",
    "        images.append(img_array)\n",
    "        labels.append(row['Label'])\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a9d0c7-2457-4de9-a6a6-cee763043ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = preprocess_images(df_train)\n",
    "val_images, val_labels = preprocess_images(df_val)\n",
    "test_images, test_labels = preprocess_images(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0228b829-3485-4246-a1d0-1655507aae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_labels)\n",
    "val_labels = label_encoder.transform(val_labels)\n",
    "test_labels = label_encoder.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea72a413-e1a5-4c18-b9fa-6db9d3fac201",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels, len(CATEGORY_DIRECTORIES))\n",
    "val_labels = to_categorical(val_labels, len(CATEGORY_DIRECTORIES))\n",
    "test_labels = to_categorical(test_labels, len(CATEGORY_DIRECTORIES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff745922-30a0-40b7-b448-eb60e0bc7fdf",
   "metadata": {},
   "source": [
    "## Model Based on Random Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f15d7d-afbd-4d6f-87ba-1fb15702f8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(GRU(units=128, return_sequences=True, input_shape=(224, 224 * 3)))\n",
    "model.add(GRU(units=64))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(len(CATEGORY_DIRECTORIES), activation=\"softmax\"))\n",
    "\n",
    "tf.keras.utils.plot_model(model, f\"{RNN_IMAGE_RESULTS}/gru_model_summary.png\", show_shapes=True, dpi=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e45c2b-92e8-4766-badb-ad2ea2e97885",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['categorical_accuracy']\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=20,\n",
    "    mode=\"min\",\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a377b8a7-7e78-4e05-a7ae-240318ab9b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get history\n",
    "history = model.fit(train_images, train_labels, validation_data=(val_images, val_labels),\n",
    "                    batch_size=32, epochs=100, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8f4948-2097-49c3-bd00-ad26890b4e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[['categorical_accuracy','val_categorical_accuracy']].plot()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()\n",
    "plt.savefig(f\"{RNN_IMAGE_RESULTS}/gru_accuracy_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65585e4c-4529-4ee7-b7e9-34e3cdd6b365",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[['loss','val_loss']].plot()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "plt.savefig(f\"{RNN_IMAGE_RESULTS}/gru_loss_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bc05c5-83c5-4dc4-8818-2ebc8c4fd1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], 'red', label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], 'green', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['categorical_accuracy'], 'orange', label='Training Accuracy')\n",
    "plt.plot(history.history['val_categorical_accuracy'], 'blue', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{RNN_IMAGE_RESULTS}/gru_training_plots.png\")\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_csv = f\"{RNN_HISTORY_RESULTS}/gru_history.csv\"\n",
    "history_df.to_csv(history_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9410fb-0091-441d-97a4-589829fef075",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_images)\n",
    "\n",
    "y_true = np.argmax(test_labels, axis=1)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dccceca-441c-428f-ac0a-26f666fa5afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_true, y_pred, target_names=label_encoder.classes_)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "report_file = f\"{RNN_REPORT_RESULTS}/gru_classification_report.txt\"\n",
    "with open(report_file, 'w') as file:\n",
    "    file.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ef9110-b9e8-4e35-b21d-3a8ff5ced8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='coolwarm', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "heatmap_file = f'{RNN_IMAGE_RESULTS}/gru_confusion_matrix.png'\n",
    "plt.savefig(heatmap_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f7e6af-fb1a-4560-b52d-042ccd1ea7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{RNN_MODEL_RESULTS}/gru.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7900b26f-1bfa-47f1-b36d-0b8956fdd231",
   "metadata": {},
   "source": [
    "## Hyper-parameter Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb950ab-2466-4319-93b9-8af325553bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_gru(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(GRU(units=hp.Int('units_gru_1', min_value=64, max_value=256, step=64),\n",
    "    input_shape=(224, 224 * 3),\n",
    "    return_sequences=True))\n",
    "\n",
    "    model.add(GRU(units=hp.Int('units_gru_2', min_value=32, max_value=128, step=32)))\n",
    "    model.add(Dropout(hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(units=hp.Int('units_dense', min_value=16, max_value=64, step=16), activation='relu'))\n",
    "    model.add(Dense(len(CATEGORY_DIRECTORIES), activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['categorical_accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4108b72-3ec1-40de-adb2-911e29cd09aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_early=EarlyStopping(monitor='val_loss', patience=50, verbose=1, mode='min', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f2dad0-38ec-4d6f-bbba-cafb70f16704",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "        build_model_gru,\n",
    "        objective=\"val_categorical_accuracy\",\n",
    "        max_trials=5,\n",
    "        executions_per_trial=1,\n",
    "        directory=\"hyperparameter_tuning\",\n",
    "        project_name='GRU'\n",
    "    )\n",
    "\n",
    "tuner.search(train_images, train_labels, validation_data=(val_images, val_labels), epochs=20, callbacks=[stop_early])\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    \n",
    "print(f\"\"\"\n",
    "Best hyperparameters:\n",
    "- Units in GRU Layer 1: {best_hps.get('units_gru_1')}\n",
    "- Units in GRU Layer 2: {best_hps.get('units_gru_2')}\n",
    "- Dropout Rate: {best_hps.get('dropout_rate')}\n",
    "- Units in Dense Layer 1: {best_hps.get('units_dense')}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5115996a-b1cd-4666-9230-7c03a73f2b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "tf.keras.utils.plot_model(model, f\"{RNN_IMAGE_RESULTS}/gru_model_hp_summary.png\", show_shapes=True, dpi=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe11570-0fb1-419d-abc3-6c446f3b76de",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_images, train_labels, validation_data=(val_images, val_labels),\n",
    "                    batch_size=32, epochs=100, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea9826d-87b3-4bee-9f90-24e93d6d77d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[['categorical_accuracy','val_categorical_accuracy']].plot()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()\n",
    "plt.savefig(f\"{RNN_IMAGE_RESULTS}/gru_hp_accuracy_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9854d7aa-24a0-411d-8d94-86b34de53f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[['loss','val_loss']].plot()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "plt.savefig(f\"{RNN_IMAGE_RESULTS}/gru_hp_loss_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295fb8d2-2025-4d08-ae99-fc2788f8b8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], 'red', label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], 'green', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['categorical_accuracy'], 'orange', label='Training Accuracy')\n",
    "plt.plot(history.history['val_categorical_accuracy'], 'blue', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{RNN_IMAGE_RESULTS}/gru_training_hp_plots.png\")\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_csv = f\"{RNN_HISTORY_RESULTS}/gru_hp_history.csv\"\n",
    "history_df.to_csv(history_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ba4b44-ea50-46de-bb64-3ba5d19c749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_images)\n",
    "\n",
    "y_true = np.argmax(test_labels, axis=1)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf7f0f5-6a7e-43a0-8b21-11d8a37ca17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_true, y_pred, target_names=label_encoder.classes_)\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "report_file = f\"{RNN_REPORT_RESULTS}/gru_hp_classification_report.txt\"\n",
    "with open(report_file, 'w') as file:\n",
    "    file.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a508d015-0a53-4fe4-820f-32bcdb3f81bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='coolwarm', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "heatmap_file = f'{RNN_IMAGE_RESULTS}/gru_hp_confusion_matrix.png'\n",
    "plt.savefig(heatmap_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc0b1a1-f479-4e6e-abac-8666c99d9b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{RNN_MODEL_RESULTS}/gru_hp.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
