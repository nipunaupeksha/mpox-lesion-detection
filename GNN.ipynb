{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc745bfd-beaa-4163-a5f6-e8f1921552e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import NeighborSampler\n",
    "from torch_geometric.nn import SAGEConv, GCNConv\n",
    "from torch_geometric import utils, loader\n",
    "from torch_geometric.utils import subgraph\n",
    "\n",
    "from torch_geometric.nn import (\n",
    "    Aggregation,\n",
    "    MaxAggregation,\n",
    "    MeanAggregation,\n",
    "    MultiAggregation,\n",
    "    SoftmaxAggregation,\n",
    "    StdAggregation,\n",
    "    SumAggregation,\n",
    "    VarAggregation,\n",
    "    LSTMAggregation\n",
    ")\n",
    "\n",
    "# importing obg datatset\n",
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator\n",
    "\n",
    "from pandas.core.common import flatten\n",
    "# import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# sns.set(rc={'figure.figsize':(16.7,8.27)})\n",
    "# sns.set_theme(style=\"ticks\")\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import collections\n",
    "import os.path as osp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "# from pandas.core.common import flatten\n",
    "# from scipy.special import softmax\n",
    "\n",
    "import random\n",
    "\n",
    "# Setting the seed\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e6bb16a-cb57-4cc8-b655-554dbb74a7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = 'GCN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "093a90a8-d73b-4034-b6d1-2d93752b2638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Load the OGB evaluator for the dataset\n",
    "evaluator = Evaluator(name='ogbn-products')\n",
    "\n",
    "# Establish the device for model training 'cuda' if GPU, 'cpu' otherwise\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "\n",
    "# Confirm the device. If it's a GPU, 'cuda' will print\n",
    "print('Device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8b56169-f68e-414e-9132-818f267299cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "This will download 1.38GB. Will you proceed? (y/N)\n",
      " y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/products.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 1.38 GB: 100%|███████████████████| 1414/1414 [02:29<00:00,  9.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/nipunaupeksha/Desktop/content/products.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading necessary files...\n",
      "This might take a while.\n",
      "Processing graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting graphs into PyG objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 1/1 [00:00<00:00, 327.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "/Users/nipunaupeksha/miniconda3/envs/msc/lib/python3.8/site-packages/ogb/nodeproppred/dataset_pyg.py:69: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n"
     ]
    }
   ],
   "source": [
    "root = osp.join(osp.dirname(osp.realpath('./')), 'content')\n",
    "if opt == 'GCN':\n",
    "  dataset = PygNodePropPredDataset( name='ogbn-products', root=root)\n",
    "else:\n",
    "  dataset = PygNodePropPredDataset( name='ogbn-products', transform=T.ToSparseTensor(), root=root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "852f695b-0f65-4341-a3bb-7c94010aa129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(num_nodes=2449029, edge_index=[2, 123718280], x=[2449029, 100], y=[2449029, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b944158c-5d8e-485f-b670-834637f9e582",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define the indices of nodes to include in your subset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m subset_indices \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10000\u001b[39m)  \u001b[38;5;66;03m# For example, first 10,000 nodes\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Extract the subgraph corresponding to the subset\u001b[39;00m\n\u001b[1;32m      6\u001b[0m subset_edge_index, edge_attr, edge_mask \u001b[38;5;241m=\u001b[39m subgraph(subset_indices, data\u001b[38;5;241m.\u001b[39medge_index, \u001b[38;5;28;01mNone\u001b[39;00m, relabel_nodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_nodes\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mnum_nodes, return_edge_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the indices of nodes to include in your subset\n",
    "subset_indices = torch.arange(0, 10000)  # For example, first 10,000 nodes\n",
    "\n",
    "\n",
    "# Extract the subgraph corresponding to the subset\n",
    "subset_edge_index, edge_attr, edge_mask = subgraph(subset_indices, data.edge_index, None, relabel_nodes=True, num_nodes=data.num_nodes, return_edge_mask=True)\n",
    "\n",
    "\n",
    "# Adjust node features and labels for the subset\n",
    "subset_features = data.x[subset_indices]\n",
    "subset_labels = data.y[subset_indices]\n",
    "\n",
    "# Create a new graph object for the subset\n",
    "subset_graph = data.__class__()\n",
    "subset_graph.edge_index = subset_edge_index\n",
    "subset_graph.x = subset_features\n",
    "subset_graph.y = subset_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a89576c8-02b5-497b-8a12-f85a505ca663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics as sk\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88d42c45-3c05-4a0f-a2bd-695476a81a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_medmnist_data(view, split):\n",
    "    \"\"\"\n",
    "    Load MedMNIST data for the given view and split.\n",
    "\n",
    "    Args:\n",
    "        view (str): Either 'c' or 's' indicating the dataset view.\n",
    "        split (str): The dataset split, one of 'train', 'val', or 'test'.\n",
    "\n",
    "    Returns:\n",
    "        (np.ndarray, np.ndarray): Tuple of images and labels.\n",
    "    \"\"\"\n",
    "    info = INFO[f'organ{view}mnist']\n",
    "    DataClass = getattr(medmnist, info['python_class'])\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    dataset = DataClass(split=split, transform=transform, download=True)\n",
    "    dataloader = DataLoader(dataset, batch_size=len(dataset), shuffle=False)\n",
    "    for data in dataloader:\n",
    "        images, labels = data\n",
    "    images = images.numpy().squeeze()\n",
    "    labels = labels.numpy().squeeze()\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aed5ffd6-bca5-4bb0-93da-5882fae3ff55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/nipunaupeksha/.medmnist/organcmnist.npz\n"
     ]
    }
   ],
   "source": [
    "views = ['c', 's']\n",
    "num_features = 28 * 28\n",
    "view = views[0]\n",
    "\n",
    "train_images, train_labels = load_medmnist_data(view, 'train')\n",
    "train_data = train_images.reshape(train_images.shape[0], num_features).astype('float')\n",
    "num_train = train_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cadd9b23-5c83-4a57-b20a-211836a95d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://zenodo.org/records/10519652/files/pathmnist.npz?download=1 to /Users/nipunaupeksha/.medmnist/pathmnist.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 205615438/205615438 [00:16<00:00, 12097939.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset PathMNIST of size 28 (pathmnist)\n",
       "    Number of datapoints: 89996\n",
       "    Root location: /Users/nipunaupeksha/.medmnist\n",
       "    Split: train\n",
       "    Task: multi-class\n",
       "    Number of channels: 3\n",
       "    Meaning of labels: {'0': 'adipose', '1': 'background', '2': 'debris', '3': 'lymphocytes', '4': 'mucus', '5': 'smooth muscle', '6': 'normal colon mucosa', '7': 'cancer-associated stroma', '8': 'colorectal adenocarcinoma epithelium'}\n",
       "    Number of samples: {'train': 89996, 'val': 10004, 'test': 7180}\n",
       "    Description: The PathMNIST is based on a prior study for predicting survival from colorectal cancer histology slides, providing a dataset (NCT-CRC-HE-100K) of 100,000 non-overlapping image patches from hematoxylin & eosin stained histological images, and a test dataset (CRC-VAL-HE-7K) of 7,180 image patches from a different clinical center. The dataset is comprised of 9 types of tissues, resulting in a multi-class classification task. We resize the source images of 3×224×224 into 3×28×28, and split NCT-CRC-HE-100K into training and validation set with a ratio of 9:1. The CRC-VAL-HE-7K is treated as the test set.\n",
       "    License: CC BY 4.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from medmnist import PathMNIST\n",
    "train_dataset = PathMNIST(split=\"train\", download=True)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6586dd-50b3-49c9-a4f7-3ebab23da1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
