{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4904fc23-d7e3-4d88-8783-f9121ef3113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import keras_tuner as kt\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from keras_tuner import Hyperband\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, f1_score\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import cv2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5d2488-70c1-452a-8a1e-7ec153741b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/original'\n",
    "CNN_IMAGE_RESULTS = './results/cnn/images'\n",
    "CNN_HISTORY_RESULTS = './results/cnn/history'\n",
    "CNN_REPORT_RESULTS = './results/cnn/reports'\n",
    "CNN_MODEL_RESULTS = './results/cnn/models'\n",
    "\n",
    "TRAIN_DIRECTORY = 'train'\n",
    "VALIDATION_DIRECTORY = 'val'\n",
    "TEST_DIRECTORY = 'test'\n",
    "\n",
    "SUB_DIRECTORIES = [TRAIN_DIRECTORY, TEST_DIRECTORY, VALIDATION_DIRECTORY]\n",
    "CATEGORY_DIRECTORIES = ['Actinic keratoses', 'Basal cell carcinoma', 'Benign keratosis-like lesions', 'Chickenpox', 'Cowpox', 'Dermatofibroma', 'Healthy', 'HFMD', 'Measles', 'Melanocytic nevi', 'Melanoma', 'Monkeypox', 'Squamous cell carcinoma', 'Vascular lesions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42d80e1-5462-40a4-aa64-61ca9228a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images(dir_name):\n",
    "    for dataset_type in SUB_DIRECTORIES:\n",
    "        total = 0\n",
    "        dir_type = os.path.join(dir_name, dataset_type)\n",
    "        print(f\"============ {dataset_type} dataset ===========\")\n",
    "        for category in os.listdir(dir_type):\n",
    "            category_path = os.path.join(dir_type, category)\n",
    "            if not os.path.isdir(category_path):\n",
    "                continue\n",
    "            images = [img for img in os.listdir(category_path) if img.endswith(('jpg','jpeg'))]\n",
    "            print(f\"Number of images in {category_path.split('/')[-1]}: {len(images)}\")\n",
    "            total += len(images)\n",
    "        print(f\"Total image count: {total}\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2fe0af-325d-4396-98c9-7d239d364868",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_images(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d448f92-6da2-4ee5-9142-102d2986cef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_to_df(base_path, dataset_type):\n",
    "    path = os.path.join(base_path, dataset_type)\n",
    "    image_dir = Path(path)\n",
    "\n",
    "    file_paths = list(image_dir.glob(r'**/*.jpg'))\n",
    "    labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], file_paths))\n",
    "\n",
    "    file_paths = pd.Series(file_paths, name='Path').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    image_df = pd.concat([file_paths, labels], axis=1)\n",
    "\n",
    "    samples = []\n",
    "    for record in image_df['Label'].unique():\n",
    "        samples.append(image_df[image_df['Label']==record])\n",
    "    image_df = pd.concat(samples, axis=0).sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    return image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91922a3-7d6c-4b6e-8838-753a486e777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load_images_to_df(DATA_PATH, TRAIN_DIRECTORY)\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7d2ff5-9f50-414c-8c79-3cefa1db1840",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = load_images_to_df(DATA_PATH, VALIDATION_DIRECTORY)\n",
    "df_val.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8567302-7992-45b9-b366-78b8312c6ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = load_images_to_df(DATA_PATH, TEST_DIRECTORY)\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a32d65-79f8-4db3-8fdc-1ad3cf1f866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie_plot_from_df(df, title):\n",
    "    pie = df[\"Label\"].value_counts()\n",
    "    pie.plot(kind=\"pie\", autopct=\"%1.2f%%\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xlabel(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f7915c-6341-4e10-b296-79dbf6e45482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_from_df(df, nrows, ncols):\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15,8), subplot_kw={\"xticks\":[], \"yticks\":[]})\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(plt.imread(df.Path[i], -1))\n",
    "        ax.set_title(df.Label[i])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26c766c-16cf-4dfe-aaf4-85dc629d351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_plot_from_df(df_train, \"Image Percentages from Train Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b00714-912e-4e71-b9a9-73055e6adf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_plot_from_df(df_val, \"Image Percentages from Val Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550a0732-e5ca-4088-aa26-da1ceb95b0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_plot_from_df(df_test, \"Image Percentages from Test Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9ec002-1be3-4c2f-891f-eb99132cab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_from_df(df_train, 6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50077bab-f2c5-4eb0-a84b-a502e46be81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_from_df(df_val, 6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ddee27-1831-46a3-98b9-5b958d0932e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_from_df(df_test, 6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b7243f-2e9d-4870-9c32-26f3bdd5b999",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=90,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    channel_shift_range=0.1,\n",
    "    fill_mode=\"nearest\",\n",
    "    preprocessing_function = tf.keras.applications.inception_v3.preprocess_input\n",
    ")\n",
    "\n",
    "val_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function = tf.keras.applications.inception_v3.preprocess_input\n",
    ")\n",
    "\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function = tf.keras.applications.inception_v3.preprocess_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75ae552-cf72-4807-ad7d-6188931224fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(generator, df, subset):\n",
    "    images = generator.flow_from_dataframe(\n",
    "        dataframe=df,\n",
    "        x_col='Path', \n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        seed=42)\n",
    "    print(f\"{subset} class indices: {images.class_indices}\\n\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219a0468-3c2c-4eea-8b77-392a660ae196",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_dataset(train_generator, df_train, TRAIN_DIRECTORY)\n",
    "val_dataset = create_dataset(val_generator, df_val, VALIDATION_DIRECTORY)\n",
    "test_dataset = create_dataset(test_generator, df_test, TEST_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bcde51-2a17-4e5a-b985-b111640ebcfd",
   "metadata": {},
   "source": [
    "## Model Based on Random Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd97ebf-5c4e-4a88-809c-4c34c6c09d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224,224,3)\n",
    ")\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "inputs = base_model.input\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "outputs = Dense(len(CATEGORY_DIRECTORIES), activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "tf.keras.utils.plot_model(model, f\"{CNN_IMAGE_RESULTS}/inception_v3_model_summary.png\", show_shapes=True, dpi=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e39b590-eaf6-45fc-b947-c6f6de51463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(train_dataset.classes),\n",
    "    y=train_dataset.classes\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=20,\n",
    "    mode=\"min\",\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e2c9d6-92a0-4e91-901b-ec4ff3a8f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=110,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[early_stopping],\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71543a30-0a2a-4261-83d5-437c7c6794dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], 'red', label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], 'green', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['categorical_accuracy'], 'orange', label='Training Accuracy')\n",
    "plt.plot(history.history['val_categorical_accuracy'], 'blue', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{CNN_IMAGE_RESULTS}/inception_v3_training_plots.png\")\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_csv = f\"{CNN_HISTORY_RESULTS}/inception_v3_history.csv\"\n",
    "history_df.to_csv(history_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10eeb0d-8d35-4d12-a1ab-a5097425f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_dataset)\n",
    "\n",
    "y_true = test_dataset.classes\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1ad128-37d5-47a6-b8b4-4ebe9ea31a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_true, y_pred, target_names=test_dataset.class_indices.keys())\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "report_file = f\"{CNN_REPORT_RESULTS}/inception_v3_classification_report.txt\"\n",
    "with open(report_file, 'w') as file:\n",
    "    file.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a0aebf-418b-4ae7-8f38-22257845202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='coolwarm', xticklabels=test_dataset.class_indices.keys(), yticklabels=test_dataset.class_indices.keys())\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "heatmap_file = f'{CNN_IMAGE_RESULTS}/inception_v3_confusion_matrix.png'\n",
    "plt.savefig(heatmap_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1add6e-ffef-4bef-9198-38d4d318931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{CNN_MODEL_RESULTS}/inception_v3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592a41a9-e34f-4b8d-9e09-fbc111c4d0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_test.sample(n=10, random_state=42)\n",
    "image_dict = dict(zip(df_sample[\"Path\"], df_sample[\"Label\"]))\n",
    "\n",
    "for path, label in image_dict.items():\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = tf.keras.applications.inception_v3.preprocess_input(img_array)\n",
    "\n",
    "    preds = model.predict(img_array)\n",
    "    predicted_class_idx = np.argmax(preds[0])\n",
    "\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    reversed_dict = {v: k for k, v in test_dataset.class_indices.items()}\n",
    "    predicted_class = reversed_dict[predicted_class_idx]\n",
    "    plt.title(f\"Original: {label} | Predicted: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9d2b21-a276-4e12-ae48-032c58054922",
   "metadata": {},
   "source": [
    "## Hyper-parameter Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4612381f-6249-4ff0-96f4-e8469c1b7278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_with_hp(hp, base_model, num_classes):\n",
    "    inputs = base_model.input\n",
    "\n",
    "    x = base_model.output\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(units=hp.Int(\"dense_1_units\", min_value=128, max_value=512, step=32), activation=\"relu\")(x)\n",
    "    x = Dropout(rate=hp.Choice(\"dropout_rate_1\", values=[0.2, 0.3, 0.4, 0.5, 0.6, 0.7]))(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(units=hp.Int('dense_2_units', min_value=32, max_value=512, step=16), activation='relu')(x)\n",
    "\n",
    "    x = Dropout(rate=hp.Choice('dropout_rate_2', values=[0.2,0.3,0.4,0.5,0.6,0.7]))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "        ),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['categorical_accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152684b8-22dd-4473-9f30-b0c04f44f91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_hyperparameter_tuning(model_name, base_model_func, train_dataset, val_dataset, num_classes, max_epochs=110):\n",
    "    base_model = base_model_func(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "    tuner = Hyperband(\n",
    "        lambda hp: build_model_with_hp(hp, base_model, num_classes),\n",
    "        objective=\"categorical_accuracy\",\n",
    "        max_epochs=max_epochs,\n",
    "        factor=3,\n",
    "        directory=\"hyperparameter_tuning\",\n",
    "        project_name=model_name\n",
    "    )\n",
    "\n",
    "    tuner.search(train_dataset, validation_data=val_dataset, epochs=max_epochs, callbacks=[EarlyStopping(monitor='val_loss', patience=50, verbose=1, mode='min', restore_best_weights=True)])\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    \n",
    "    print(f\"Best hyperparameters for {model_name}:\")\n",
    "    print(f\" - Units: {best_hps.get('units')}\")\n",
    "    print(f\" - Dropout Rate: {best_hps.get('dropout_rate')}\")\n",
    "    print(f\" - Learning Rate: {best_hps.get('learning_rate')}\")\n",
    "    \n",
    "    return tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdcd707-74a6-42c7-97ce-4223eab8ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = perform_hyperparameter_tuning(\"InceptionV3\", InceptionV3, train_dataset, val_dataset, len(CATEGORY_DIRECTORIES))\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = build_model_with_hp(best_hps, base_model, len(CATEGORY_DIRECTORIES))\n",
    "tf.keras.utils.plot_model(model, f\"{CNN_IMAGE_RESULTS}/inception_v3_hp_model_summary.png\", show_shapes=True, dpi=50)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(train_dataset.classes),\n",
    "    y=train_dataset.classes\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=110,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=50, verbose=1, mode='min', restore_best_weights=True)],\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d708b3-e803-479c-a74c-dcb21d6fdb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], 'red', label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], 'green', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['categorical_accuracy'], 'orange', label='Training Accuracy')\n",
    "plt.plot(history.history['val_categorical_accuracy'], 'blue', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{CNN_IMAGE_RESULTS}/inception_v3_hp_training_plots.png\")\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_csv = f\"{CNN_HISTORY_RESULTS}/inception_v3_hp_history.csv\"\n",
    "history_df.to_csv(history_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d411685-3360-4c5a-89b5-2ec896f4939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_dataset)\n",
    "\n",
    "y_true = test_dataset.classes\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2c3bb1-9371-4689-b01f-438b9e33e3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_true, y_pred, target_names=test_dataset.class_indices.keys())\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "report_file = f\"{CNN_REPORT_RESULTS}/inception_v3_hp_classification_report.txt\"\n",
    "with open(report_file, 'w') as file:\n",
    "    file.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e794605-22e2-488d-a4a4-1134e2c9d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='coolwarm', xticklabels=test_dataset.class_indices.keys(), yticklabels=test_dataset.class_indices.keys())\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "heatmap_file = f'{CNN_IMAGE_RESULTS}/inception_v3_hp_confusion_matrix.png'\n",
    "plt.savefig(heatmap_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c99f5a-ce39-4e25-9e90-0be8052c3a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{CNN_MODEL_RESULTS}/inception_v3_hp.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ed4304-a88d-45ca-9bbe-2712e079fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_test.sample(n=10, random_state=42)\n",
    "image_dict = dict(zip(df_sample[\"Path\"], df_sample[\"Label\"]))\n",
    "\n",
    "for path, label in image_dict:\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = tf.keras.applications.inception_v3.preprocess_input(img_array)\n",
    "\n",
    "    preds = model.predict(img_array)\n",
    "    predicted_class_idx = np.argmax(preds[0])\n",
    "\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    reversed_dict = {v: k for k, v in test_dataset.class_indices.items()}\n",
    "    predicted_class = reversed_dict[predicted_class_idx]\n",
    "    plt.title(f\"Original: {} | Predicted: {predicted_class}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
