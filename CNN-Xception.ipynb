{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17e22534-9ece-446b-bd37-18d790e43b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import keras_tuner as kt\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from keras_tuner import Hyperband\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, f1_score\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import cv2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a056a88-baeb-49be-9176-b83c28516b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/original'\n",
    "CNN_IMAGE_RESULTS = './results/cnn/images'\n",
    "CNN_HISTORY_RESULTS = './results/cnn/history'\n",
    "CNN_REPORT_RESULTS = './results/cnn/reports'\n",
    "CNN_MODEL_RESULTS = './results/cnn/models'\n",
    "\n",
    "TRAIN_DIRECTORY = 'train'\n",
    "VALIDATION_DIRECTORY = 'val'\n",
    "TEST_DIRECTORY = 'test'\n",
    "\n",
    "SUB_DIRECTORIES = [TRAIN_DIRECTORY, TEST_DIRECTORY, VALIDATION_DIRECTORY]\n",
    "CATEGORY_DIRECTORIES = ['Actinic keratoses', 'Basal cell carcinoma', 'Benign keratosis-like lesions', 'Chickenpox', 'Cowpox', 'Dermatofibroma', 'Healthy', 'HFMD', 'Measles', 'Melanocytic nevi', 'Melanoma', 'Monkeypox', 'Squamous cell carcinoma', 'Vascular lesions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ffbadd-c4c7-49fa-9aaf-1f49ebdeea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images(dir_name):\n",
    "    for dataset_type in SUB_DIRECTORIES:\n",
    "        total = 0\n",
    "        dir_type = os.path.join(dir_name, dataset_type)\n",
    "        print(f\"============ {dataset_type} dataset ===========\")\n",
    "        for category in os.listdir(dir_type):\n",
    "            category_path = os.path.join(dir_type, category)\n",
    "            if not os.path.isdir(category_path):\n",
    "                continue\n",
    "            images = [img for img in os.listdir(category_path) if img.endswith(('jpg','jpeg'))]\n",
    "            print(f\"Number of images in {category_path.split('/')[-1]}: {len(images)}\")\n",
    "            total += len(images)\n",
    "        print(f\"Total image count: {total}\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f210b08-70e6-4fb2-ad15-aa3a7281f003",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_images(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f2be11-6683-4529-9625-071595b4f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_to_df(base_path, dataset_type):\n",
    "    path = os.path.join(base_path, dataset_type)\n",
    "    image_dir = Path(path)\n",
    "\n",
    "    file_paths = list(image_dir.glob(r'**/*.jpg'))\n",
    "    labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], file_paths))\n",
    "\n",
    "    file_paths = pd.Series(file_paths, name='Path').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    image_df = pd.concat([file_paths, labels], axis=1)\n",
    "\n",
    "    samples = []\n",
    "    for record in image_df['Label'].unique():\n",
    "        samples.append(image_df[image_df['Label']==record])\n",
    "    image_df = pd.concat(samples, axis=0).sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    return image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c7541-2f93-4538-9adc-94f697a3eb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load_images_to_df(DATA_PATH, TRAIN_DIRECTORY)\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275f0575-d04e-4195-be21-94c52de4fc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = load_images_to_df(DATA_PATH, VALIDATION_DIRECTORY)\n",
    "df_val.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ff3e13-7f39-4cee-9afd-68d6903b4f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = load_images_to_df(DATA_PATH, TEST_DIRECTORY)\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a13a93b-6558-4ca1-8bd2-8bff76804d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie_plot_from_df(df, title):\n",
    "    pie = df[\"Label\"].value_counts()\n",
    "    pie.plot(kind=\"pie\", autopct=\"%1.2f%%\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xlabel(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da846a24-b1d4-4b3f-b131-6c2a34dfb5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_from_df(df, nrows, ncols):\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15,8), subplot_kw={\"xticks\":[], \"yticks\":[]})\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(plt.imread(df.Path[i], -1))\n",
    "        ax.set_title(df.Label[i])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195b6d6a-10e7-40f7-9a31-6dafc5e3855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_plot_from_df(df_train, \"Image Percentages from Train Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e138bb-6d02-4abd-bbaf-8f02f17c3f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_plot_from_df(df_val, \"Image Percentages from Val Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38612b5-7f53-48ef-9fd9-22edead271d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_plot_from_df(df_test, \"Image Percentages from Test Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d11303-43a3-4e6a-9c1b-b4a0fec952be",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_from_df(df_train, 6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab537d54-3c3c-499f-a54b-b80f8ca1dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_from_df(df_val, 6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105678b5-19ab-41fd-a064-a7a8a0ce4664",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_from_df(df_test, 6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbe1884-e00a-46fd-a4fc-8d5208fa048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=90,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    channel_shift_range=0.1,\n",
    "    fill_mode=\"nearest\",\n",
    "    preprocessing_function = tf.keras.applications.xception.preprocess_input\n",
    ")\n",
    "\n",
    "val_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function = tf.keras.applications.xception.preprocess_input\n",
    ")\n",
    "\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function = tf.keras.applications.xception.preprocess_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb508d7b-a867-4b56-98a4-1423ee1a35a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(generator, df, subset):\n",
    "    images = generator.flow_from_dataframe(\n",
    "        dataframe=df,\n",
    "        x_col='Path', \n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        seed=42)\n",
    "    print(f\"{subset} class indices: {images.class_indices}\\n\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bc3f2b-b706-42f4-b737-20fae92dec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_dataset(train_generator, df_train, TRAIN_DIRECTORY)\n",
    "val_dataset = create_dataset(val_generator, df_val, VALIDATION_DIRECTORY)\n",
    "test_dataset = create_dataset(test_generator, df_test, TEST_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464cd32d-59a6-4b1f-a520-f2925d143d87",
   "metadata": {},
   "source": [
    "## Model Based on Random Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f1a26d-e850-4f44-979c-76a357ce7af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = Xception(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224,224,3)\n",
    ")\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "inputs = base_model.input\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "outputs = Dense(len(CATEGORY_DIRECTORIES), activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "tf.keras.utils.plot_model(model, f\"{CNN_IMAGE_RESULTS}/xception_model_summary.png\", show_shapes=True, dpi=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af42e30-51f9-433a-96c0-c267f06e2b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(train_dataset.classes),\n",
    "    y=train_dataset.classes\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=20,\n",
    "    mode=\"min\",\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a044eb-8e71-41d8-88b6-949795e549aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=110,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[early_stopping],\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc35670e-d07a-44a4-a316-7523896e2d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], 'red', label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], 'green', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['categorical_accuracy'], 'orange', label='Training Accuracy')\n",
    "plt.plot(history.history['val_categorical_accuracy'], 'blue', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{CNN_IMAGE_RESULTS}/xception_training_plots.png\")\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_csv = f\"{CNN_HISTORY_RESULTS}/xception_history.csv\"\n",
    "history_df.to_csv(history_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57221087-aac7-47f2-91da-32a7fa3ce23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_dataset)\n",
    "\n",
    "y_true = test_dataset.classes\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a468877-7dbf-40a2-abe1-5cd28e816893",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_true, y_pred, target_names=test_dataset.class_indices.keys())\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "report_file = f\"{CNN_REPORT_RESULTS}/xception_classification_report.txt\"\n",
    "with open(report_file, 'w') as file:\n",
    "    file.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6471568-8e7c-4f6f-9922-f8f861b93daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='coolwarm', xticklabels=test_dataset.class_indices.keys(), yticklabels=test_dataset.class_indices.keys())\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "heatmap_file = f'{CNN_IMAGE_RESULTS}/xception_confusion_matrix.png'\n",
    "plt.savefig(heatmap_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38fece0-1e4c-442a-9c3b-0e8f5ee5bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{CNN_MODEL_RESULTS}/xception.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f128c793-2d5d-42cf-8790-7adfc2897514",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_test.sample(n=10, random_state=42)\n",
    "image_dict = dict(zip(df_sample[\"Path\"], df_sample[\"Label\"]))\n",
    "\n",
    "for path, label in image_dict.items():\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = tf.keras.applications.inception_resnet_v2.preprocess_input(img_array)\n",
    "\n",
    "    preds = model.predict(img_array)\n",
    "    predicted_class_idx = np.argmax(preds[0])\n",
    "\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    reversed_dict = {v: k for k, v in test_dataset.class_indices.items()}\n",
    "    predicted_class = reversed_dict[predicted_class_idx]\n",
    "    plt.title(f\"Original: {label} | Predicted: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f297b911-2474-4d8b-9305-6e61f1b8a89a",
   "metadata": {},
   "source": [
    "## Hyper-parameter Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3b35c7-a9e9-4e95-a8c1-d758552e577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_with_hp(hp, base_model, num_classes):\n",
    "    inputs = base_model.input\n",
    "\n",
    "    x = base_model.output\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(units=hp.Int(\"dense_1_units\", min_value=128, max_value=512, step=32), activation=\"relu\")(x)\n",
    "    x = Dropout(rate=hp.Choice(\"dropout_rate_1\", values=[0.2, 0.3, 0.4, 0.5, 0.6, 0.7]))(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(units=hp.Int('dense_2_units', min_value=32, max_value=512, step=16), activation='relu')(x)\n",
    "\n",
    "    x = Dropout(rate=hp.Choice('dropout_rate_2', values=[0.2,0.3,0.4,0.5,0.6,0.7]))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "        ),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['categorical_accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fa9391-b313-4325-b5ab-67cd40180cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_hyperparameter_tuning(model_name, base_model_func, train_dataset, val_dataset, num_classes, max_epochs=110, max_trials=5):\n",
    "    base_model = base_model_func(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "    # tuner = Hyperband(\n",
    "    #     lambda hp: build_model_with_hp(hp, base_model, num_classes),\n",
    "    #     objective=\"categorical_accuracy\",\n",
    "    #     max_epochs=max_epochs,\n",
    "    #     factor=3,\n",
    "    #     directory=\"hyperparameter_tuning\",\n",
    "    #     project_name=model_name\n",
    "    # )\n",
    "\n",
    "    tuner = RandomSearch(\n",
    "        lambda hp: build_model_with_hp(hp, base_model, num_classes),\n",
    "        objective=\"val_categorical_accuracy\",\n",
    "        max_trials=max_trials,  # Restrict to 5 trials\n",
    "        executions_per_trial=1,\n",
    "        directory=\"hyperparameter_tuning\",\n",
    "        project_name=model_name\n",
    "    )\n",
    "\n",
    "    tuner.search(train_dataset, validation_data=val_dataset, epochs=max_epochs, callbacks=[EarlyStopping(monitor='val_loss', patience=50, verbose=1, mode='min', restore_best_weights=True)])\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    \n",
    "    return tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aad7f1-61b7-4c5a-821f-9c529567e4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = perform_hyperparameter_tuning(\"Xception\", Xception, train_dataset, val_dataset, len(CATEGORY_DIRECTORIES))\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = build_model_with_hp(best_hps, base_model, len(CATEGORY_DIRECTORIES))\n",
    "tf.keras.utils.plot_model(model, f\"{CNN_IMAGE_RESULTS}/xception_hp_model_summary.png\", show_shapes=True, dpi=50)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(train_dataset.classes),\n",
    "    y=train_dataset.classes\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=110,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=50, verbose=1, mode='min', restore_best_weights=True)],\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53711cec-39e4-4d72-b154-608eec1d9c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], 'red', label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], 'green', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['categorical_accuracy'], 'orange', label='Training Accuracy')\n",
    "plt.plot(history.history['val_categorical_accuracy'], 'blue', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{CNN_IMAGE_RESULTS}/xception_hp_training_plots.png\")\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_csv = f\"{CNN_HISTORY_RESULTS}/xception_hp_history.csv\"\n",
    "history_df.to_csv(history_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb6d061-0c52-4e6f-8f22-657f195e8198",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_dataset)\n",
    "\n",
    "y_true = test_dataset.classes\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb8796c-b218-48e2-994b-e43904bc1891",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_true, y_pred, target_names=test_dataset.class_indices.keys())\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "report_file = f\"{CNN_REPORT_RESULTS}/xception_hp_classification_report.txt\"\n",
    "with open(report_file, 'w') as file:\n",
    "    file.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ae2c31-3530-47e5-bafd-726ba6fc1825",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='coolwarm', xticklabels=test_dataset.class_indices.keys(), yticklabels=test_dataset.class_indices.keys())\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "heatmap_file = f'{CNN_IMAGE_RESULTS}/xception_hp_confusion_matrix.png'\n",
    "plt.savefig(heatmap_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e51098-5b99-47eb-b980-ba6c7659fccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{CNN_MODEL_RESULTS}/xception_hp.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8002099e-2c8e-4dad-abd4-449336935864",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_test.sample(n=10, random_state=42)\n",
    "image_dict = dict(zip(df_sample[\"Path\"], df_sample[\"Label\"]))\n",
    "\n",
    "for path, label in image_dict:\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = tf.keras.applications.inception_resnet_v2.preprocess_input(img_array)\n",
    "\n",
    "    preds = model.predict(img_array)\n",
    "    predicted_class_idx = np.argmax(preds[0])\n",
    "\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    reversed_dict = {v: k for k, v in test_dataset.class_indices.items()}\n",
    "    predicted_class = reversed_dict[predicted_class_idx]\n",
    "    plt.title(f\"Original: {} | Predicted: {predicted_class}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
