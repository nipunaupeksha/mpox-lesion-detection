{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd733832-fc87-4f15-8042-435240905d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import keras_tuner as kt\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from keras_tuner import Hyperband\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, f1_score\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "import cv2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1874ac-0557-4570-89e5-a04f3182e2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/original'\n",
    "CNN_IMAGE_RESULTS = './results/cnn/images'\n",
    "CNN_HISTORY_RESULTS = './results/cnn/history'\n",
    "CNN_REPORT_RESULTS = './results/cnn/reports'\n",
    "CNN_MODEL_RESULTS = './results/cnn/models'\n",
    "\n",
    "TRAIN_DIRECTORY = 'train'\n",
    "VALIDATION_DIRECTORY = 'val'\n",
    "TEST_DIRECTORY = 'test'\n",
    "\n",
    "SUB_DIRECTORIES = [TRAIN_DIRECTORY, TEST_DIRECTORY, VALIDATION_DIRECTORY]\n",
    "CATEGORY_DIRECTORIES = ['Actinic keratoses', 'Basal cell carcinoma', 'Benign keratosis-like lesions', 'Chickenpox', 'Cowpox', 'Dermatofibroma', 'Healthy', 'HFMD', 'Measles', 'Melanocytic nevi', 'Melanoma', 'Monkeypox', 'Squamous cell carcinoma', 'Vascular lesions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed3ecf0-0ba4-4651-9e89-1cffbdbd0f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images(dir_name):\n",
    "    for dataset_type in SUB_DIRECTORIES:\n",
    "        total = 0\n",
    "        dir_type = os.path.join(dir_name, dataset_type)\n",
    "        print(f\"============ {dataset_type} dataset ===========\")\n",
    "        for category in os.listdir(dir_type):\n",
    "            category_path = os.path.join(dir_type, category)\n",
    "            if not os.path.isdir(category_path):\n",
    "                continue\n",
    "            images = [img for img in os.listdir(category_path) if img.endswith(('jpg','jpeg'))]\n",
    "            print(f\"Number of images in {category_path.split('/')[-1]}: {len(images)}\")\n",
    "            total += len(images)\n",
    "        print(f\"Total image count: {total}\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d2350c-391e-43c3-b6f6-0062752ea9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_images(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d0cd39-9ec7-49b4-bfc7-7efac5540788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_to_df(base_path, dataset_type):\n",
    "    path = os.path.join(base_path, dataset_type)\n",
    "    image_dir = Path(path)\n",
    "\n",
    "    file_paths = list(image_dir.glob(r'**/*.jpg'))\n",
    "    labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], file_paths))\n",
    "\n",
    "    file_paths = pd.Series(file_paths, name='Path').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    image_df = pd.concat([file_paths, labels], axis=1)\n",
    "\n",
    "    samples = []\n",
    "    for record in image_df['Label'].unique():\n",
    "        samples.append(image_df[image_df['Label']==record])\n",
    "    image_df = pd.concat(samples, axis=0).sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    return image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3807961b-d145-4c0d-bd26-015e476e0c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = load_images_to_df(DATA_PATH, TRAIN_DIRECTORY)\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cc838c-6f6c-48a2-b295-2c7a3c06d9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = load_images_to_df(DATA_PATH, VALIDATION_DIRECTORY)\n",
    "df_val.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2094bf-5ac6-4fcf-9d95-615c3ea708b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = load_images_to_df(DATA_PATH, TEST_DIRECTORY)\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e2005e-30e2-4a26-a00e-f9b3d42ef6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pie_plot_from_df(df, title):\n",
    "    pie = df[\"Label\"].value_counts()\n",
    "    pie.plot(kind=\"pie\", autopct=\"%1.2f%%\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.xlabel(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe64f93-21b6-4c7a-babe-7ede27666776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_from_df(df, nrows, ncols):\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15,8), subplot_kw={\"xticks\":[], \"yticks\":[]})\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(plt.imread(df.Path[i], -1))\n",
    "        ax.set_title(df.Label[i])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a986c-8c4c-4d05-b11a-723d0024af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_plot_from_df(df_train, \"Image Percentages from Train Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef188c8-b3cf-4d8a-83f7-d84fdc2bc3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_plot_from_df(df_val, \"Image Percentages from Val Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f428cc-b46d-49ec-bd10-40977a9e8c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_plot_from_df(df_test, \"Image Percentages from Test Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a88a64-7cf3-49ed-b2c2-1d86d925b6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_from_df(df_train, 6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7889fd8a-c6d0-4c61-a184-c892e2a509bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_from_df(df_val, 6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946200dc-623e-44a6-bc7c-545220f133f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images_from_df(df_test, 6, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aedd212-7372-4c52-a98c-d6df7690f781",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=90,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.9, 1.1],\n",
    "    channel_shift_range=0.1,\n",
    "    fill_mode=\"nearest\",\n",
    "    preprocessing_function = tf.keras.applications.resnet_v2.preprocess_input\n",
    ")\n",
    "\n",
    "val_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function = tf.keras.applications.resnet_v2.preprocess_input\n",
    ")\n",
    "\n",
    "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    preprocessing_function = tf.keras.applications.resnet_v2.preprocess_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263d481e-01f9-4787-8b61-86f0a89f0952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(generator, df, subset):\n",
    "    images = generator.flow_from_dataframe(\n",
    "        dataframe=df,\n",
    "        x_col='Path', \n",
    "        y_col='Label',\n",
    "        target_size=(224, 224),\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical',\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        seed=42)\n",
    "    print(f\"{subset} class indices: {images.class_indices}\\n\")\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe4edfb-0114-485f-869d-f88225e59659",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_dataset(train_generator, df_train, TRAIN_DIRECTORY)\n",
    "val_dataset = create_dataset(val_generator, df_val, VALIDATION_DIRECTORY)\n",
    "test_dataset = create_dataset(test_generator, df_test, TEST_DIRECTORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50959ced-9121-43f9-a2b4-719e0094b8e6",
   "metadata": {},
   "source": [
    "## Model Based on Random Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0a1b8b-0da7-4cc9-8bd0-a1ed4160168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = ResNet50V2(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224,224,3)\n",
    ")\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "inputs = base_model.input\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(64, activation=\"relu\")(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "outputs = Dense(len(CATEGORY_DIRECTORIES), activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "tf.keras.utils.plot_model(model, f\"{CNN_IMAGE_RESULTS}/res_net_v2_model_summary.png\", show_shapes=True, dpi=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e21c2d-5f5f-4a1c-bef3-85ac08116aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(train_dataset.classes),\n",
    "    y=train_dataset.classes\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=20,\n",
    "    mode=\"min\",\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e83dc50-8521-4eeb-8ec9-7bfeb1155305",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=110,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[early_stopping],\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e81b429-c633-4e96-97fb-3bb81b9cc322",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], 'red', label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], 'green', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['categorical_accuracy'], 'orange', label='Training Accuracy')\n",
    "plt.plot(history.history['val_categorical_accuracy'], 'blue', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{CNN_IMAGE_RESULTS}/res_net_v2_training_plots.png\")\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_csv = f\"{CNN_HISTORY_RESULTS}/res_net_v2_history.csv\"\n",
    "history_df.to_csv(history_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc36b70-afc7-493b-a7b8-71a0f7009cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_dataset)\n",
    "\n",
    "y_true = test_dataset.classes\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bdb305-8b7a-42b2-8db7-6dc5678331c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_true, y_pred, target_names=test_dataset.class_indices.keys())\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "report_file = f\"{CNN_REPORT_RESULTS}/res_net_v2_classification_report.txt\"\n",
    "with open(report_file, 'w') as file:\n",
    "    file.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a443ef1-fa2c-4a9f-863b-b6b65f6c75b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='coolwarm', xticklabels=test_dataset.class_indices.keys(), yticklabels=test_dataset.class_indices.keys())\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "heatmap_file = f'{CNN_IMAGE_RESULTS}/res_net_v2_confusion_matrix.png'\n",
    "plt.savefig(heatmap_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027a416f-fae2-4f22-b287-ef44c3c4a799",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{CNN_MODEL_RESULTS}/res_net_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b1310e-1bfe-42b8-8025-a202089b5454",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_test.sample(n=10, random_state=42)\n",
    "image_dict = dict(zip(df_sample[\"Path\"], df_sample[\"Label\"]))\n",
    "\n",
    "for path, label in image_dict.items():\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = tf.keras.applications.resnet_v2.preprocess_input(img_array)\n",
    "\n",
    "    preds = model.predict(img_array)\n",
    "    predicted_class_idx = np.argmax(preds[0])\n",
    "\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    reversed_dict = {v: k for k, v in test_dataset.class_indices.items()}\n",
    "    predicted_class = reversed_dict[predicted_class_idx]\n",
    "    plt.title(f\"Original: {label} | Predicted: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af7e913-34ac-4030-a287-832cfa9dc584",
   "metadata": {},
   "source": [
    "## Hyper-parameter Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5ec932-cfe3-49aa-b9c2-b2c9410c1179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_with_hp(hp, base_model, num_classes):\n",
    "    inputs = base_model.input\n",
    "\n",
    "    x = base_model.output\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(units=hp.Int(\"dense_1_units\", min_value=128, max_value=512, step=32), activation=\"relu\")(x)\n",
    "    x = Dropout(rate=hp.Choice(\"dropout_rate_1\", values=[0.2, 0.3, 0.4, 0.5, 0.6, 0.7]))(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dense(units=hp.Int('dense_2_units', min_value=32, max_value=512, step=16), activation='relu')(x)\n",
    "\n",
    "    x = Dropout(rate=hp.Choice('dropout_rate_2', values=[0.2,0.3,0.4,0.5,0.6,0.7]))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(\n",
    "        optimizer=Adam(\n",
    "            learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "        ),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['categorical_accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfab1168-42dd-4050-a592-fed8fb144758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_hyperparameter_tuning(model_name, base_model_func, train_dataset, val_dataset, num_classes, max_epochs=110, max_trials=5):\n",
    "    base_model = base_model_func(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "    # tuner = Hyperband(\n",
    "    #     lambda hp: build_model_with_hp(hp, base_model, num_classes),\n",
    "    #     objective=\"categorical_accuracy\",\n",
    "    #     max_epochs=max_epochs,\n",
    "    #     factor=3,\n",
    "    #     directory=\"hyperparameter_tuning\",\n",
    "    #     project_name=model_name\n",
    "    # )\n",
    "\n",
    "    tuner = RandomSearch(\n",
    "        lambda hp: build_model_with_hp(hp, base_model, num_classes),\n",
    "        objective=\"val_categorical_accuracy\",\n",
    "        max_trials=max_trials,  # Restrict to 5 trials\n",
    "        executions_per_trial=1,\n",
    "        directory=\"hyperparameter_tuning\",\n",
    "        project_name=model_name\n",
    "    )\n",
    "\n",
    "    tuner.search(train_dataset, validation_data=val_dataset, epochs=max_epochs, callbacks=[EarlyStopping(monitor='val_loss', patience=50, verbose=1, mode='min', restore_best_weights=True)])\n",
    "    best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "    \n",
    "    return tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de988701-dd9b-44e8-b3b9-4f8d2d1c49ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = perform_hyperparameter_tuning(\"ResNet50V2\", ResNet50V2, train_dataset, val_dataset, len(CATEGORY_DIRECTORIES))\n",
    "\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "base_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = build_model_with_hp(best_hps, base_model, len(CATEGORY_DIRECTORIES))\n",
    "tf.keras.utils.plot_model(model, f\"{CNN_IMAGE_RESULTS}/res_net_v2_hp_model_summary.png\", show_shapes=True, dpi=50)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(train_dataset.classes),\n",
    "    y=train_dataset.classes\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=110,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[EarlyStopping(monitor='val_loss', patience=50, verbose=1, mode='min', restore_best_weights=True)],\n",
    "    class_weight=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10de8795-2d12-4fb9-b23e-a5c95b2b5523",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], 'red', label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], 'green', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['categorical_accuracy'], 'orange', label='Training Accuracy')\n",
    "plt.plot(history.history['val_categorical_accuracy'], 'blue', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{CNN_IMAGE_RESULTS}/res_net_v2_hp_training_plots.png\")\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_csv = f\"{CNN_HISTORY_RESULTS}/res_net_v2_hp_history.csv\"\n",
    "history_df.to_csv(history_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0349f246-da84-4076-ad76-32881dc89dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_dataset)\n",
    "\n",
    "y_true = test_dataset.classes\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ee799c-20ff-4181-ab0c-8dc2c7f1cb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = classification_report(y_true, y_pred, target_names=test_dataset.class_indices.keys())\n",
    "print(\"Classification Report:\\n\", report)\n",
    "\n",
    "report_file = f\"{CNN_REPORT_RESULTS}/res_net_v2_hp_classification_report.txt\"\n",
    "with open(report_file, 'w') as file:\n",
    "    file.write(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6472f72d-0bdf-4a57-8419-5563276e4dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='coolwarm', xticklabels=test_dataset.class_indices.keys(), yticklabels=test_dataset.class_indices.keys())\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "\n",
    "heatmap_file = f'{CNN_IMAGE_RESULTS}/res_net_v2_hp_confusion_matrix.png'\n",
    "plt.savefig(heatmap_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89408be3-d4ee-4f26-9214-cd3fd2629b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(f\"{CNN_MODEL_RESULTS}/res_net_v2_hp.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d629ad-19ef-4f65-a007-47135901c8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_test.sample(n=10, random_state=42)\n",
    "image_dict = dict(zip(df_sample[\"Path\"], df_sample[\"Label\"]))\n",
    "\n",
    "for path, label in image_dict:\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = tf.keras.applications.resnet_v2.preprocess_input(img_array)\n",
    "\n",
    "    preds = model.predict(img_array)\n",
    "    predicted_class_idx = np.argmax(preds[0])\n",
    "\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    reversed_dict = {v: k for k, v in test_dataset.class_indices.items()}\n",
    "    predicted_class = reversed_dict[predicted_class_idx]\n",
    "    plt.title(f\"Original: {} | Predicted: {predicted_class}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
