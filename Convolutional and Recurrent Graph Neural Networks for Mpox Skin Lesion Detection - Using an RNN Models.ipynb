{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c053e8d-353a-4eed-85f7-fb25a0262389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986efa5a-02f1-4c9b-9b0c-e884e331a255",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Directory paths\n",
    "DATA_PATH = './data/original'\n",
    "AUGMENTED_PATH = './data/rnn_augmented'\n",
    "RNN_BALANCED_PATH = './data/rnn_balanced'\n",
    "MODELS_PATH = './models/rnn'\n",
    "\n",
    "TRAIN_DIRECTORY='train'\n",
    "TEST_DIRECTORY='test'\n",
    "VALIDATION_DIRECTORY ='val'\n",
    "\n",
    "### Sample Values\n",
    "TRAIN_DATASET_SAMPLE_COUNT=1000\n",
    "TEST_DATASET_SAMPLE_COUNT=200\n",
    "VALIDATION_DATASET_SAMPLE_COUNT=200\n",
    "\n",
    "### Directories containing the images\n",
    "SUB_DIRECTORIES = [TRAIN_DIRECTORY, TEST_DIRECTORY, VALIDATION_DIRECTORY]\n",
    "DATA_DIRECTORIES = ['Actinic keratoses', 'Basal cell carcinoma', 'Benign keratosis-like lesions', 'Chickenpox', 'Cowpox', 'Dermatofibroma', 'Healthy', 'HFMD', 'Measles', 'Melanocytic nevi', 'Melanoma', 'Monkeypox', 'Squamous cell carcinoma', 'Vascular lesions']\n",
    "\n",
    "### Data generation properties\n",
    "ROTATION_RANGE = 40\n",
    "WIDTH_SHIFT_RANGE = 0.2\n",
    "HEIGHT_SHIFT_RANGE = 0.2\n",
    "SHEAR_RANGE = 0.2\n",
    "ZOOM_RANGE = 0.2\n",
    "HORIZONTAL_FLIP = True\n",
    "FILL_MODE = 'nearest'\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "NUM_CLASSES = len(DATA_DIRECTORIES)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc797496-a5e3-4900-b401-fba8aa7071de",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This method is used to get the number of images in each of the directories in our dataset\n",
    "\n",
    "def count_images(dir_name):\n",
    "    for dataset_type in SUB_DIRECTORIES:\n",
    "        dir_type = os.path.join(dir_name, dataset_type)\n",
    "        print(f\"{dataset_type}\")\n",
    "        print(\"----------------------------\")\n",
    "        for category in os.listdir(dir_type):\n",
    "            category_path = os.path.join(dir_type, category)\n",
    "            if not os.path.isdir(category_path):\n",
    "                continue\n",
    "            images = [img for img in os.listdir(category_path) if img.endswith(('jpg', 'jpeg'))]\n",
    "            print(f\"Number of images in {category_path.split('/')[-1]}: {len(images)}\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd17377a-340c-4af3-9f7c-12d9d7161fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Execute the method\n",
    "\n",
    "count_images(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce8ce48-d565-4e29-96c1-e49ffb7d1cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## üóúÔ∏è Image Augmentation for Categories with Low Image Count\n",
    "\n",
    "### Define directories that lack the images count\n",
    "TRAIN_IMAGE_AUGEMENTATION_DIRS = ['Cowpox', 'Actinic keratoses', 'Measles', 'Chickenpox', 'Squamous cell carcinoma', 'Dermatofibroma', 'Vascular lesions']\n",
    "TEST_IMAGE_AUGEMENTATION_DIRS = ['Cowpox', 'Healthy', 'Actinic keratoses', 'Measles', 'Chickenpox', 'Squamous cell carcinoma', 'Dermatofibroma', 'Vascular lesions']\n",
    "VAL_IMAGE_AUGEMENTATION_DIRS = ['Cowpox', 'Healthy', 'Actinic keratoses', 'Measles', 'Chickenpox', 'Squamous cell carcinoma', 'Dermatofibroma', 'Vascular lesions']\n",
    "\n",
    "### Create Image Generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=ROTATION_RANGE,\n",
    "    width_shift_range=WIDTH_SHIFT_RANGE,\n",
    "    height_shift_range=HEIGHT_SHIFT_RANGE,\n",
    "    shear_range=SHEAR_RANGE,\n",
    "    zoom_range=ZOOM_RANGE,\n",
    "    horizontal_flip=HORIZONTAL_FLIP,\n",
    "    fill_mode=FILL_MODE)\n",
    "\n",
    "### Function to process and augment data\n",
    "def augment_and_copy_data(dir_name):\n",
    "    for dataset_type in SUB_DIRECTORIES:\n",
    "        dir_type = os.path.join(dir_name, dataset_type)\n",
    "        ### Dependeing on the dataset_type pick the categories with less number of images\n",
    "        categories = []\n",
    "        if dataset_type == TRAIN_DIRECTORY:\n",
    "            categories = TRAIN_IMAGE_AUGEMENTATION_DIRS\n",
    "        elif dataset_type == TEST_DIRECTORY:\n",
    "            categories = TEST_IMAGE_AUGEMENTATION_DIRS\n",
    "        else:\n",
    "            categories = VAL_IMAGE_AUGEMENTATION_DIRS\n",
    "        for category in categories:\n",
    "            category_path = os.path.join(dir_type, category)\n",
    "            ### Get augmented dataset path (e.g. ./data/augmented/train)\n",
    "            augmented_path = os.path.join(AUGMENTED_PATH, dataset_type)\n",
    "            ### Create the dataset type directory if it does not exist\n",
    "            os.makedirs(augmented_path, exist_ok=True)\n",
    "            ### Get augmented category path (e.g. ./data/augmented/train/Cowpox)\n",
    "            augmented_category_path = os.path.join(augmented_path, category)\n",
    "            ### Create a directory if it does not exist\n",
    "            os.makedirs(augmented_category_path, exist_ok=True)\n",
    "\n",
    "            ### Get all the files inside a category directory\n",
    "            files = os.listdir(category_path)\n",
    "\n",
    "            print(f'Started augmenting images in: {category_path}')\n",
    "\n",
    "            ### Iterate files\n",
    "            for file in files:\n",
    "                if file.startswith('.'): ### Skip hidden files\n",
    "                    continue\n",
    "                ### Load images\n",
    "                img_path = os.path.join(category_path, file)\n",
    "                img = load_img(str(img_path))\n",
    "                x = img_to_array(img) ### This is a NumPy array with shape (3, 150, 150)\n",
    "                x = x.reshape((1,) + x.shape) ### This is a NumPy array with shape (1, 3, 150, 150)\n",
    "                ### The .flow() command generates batches of randomly transformed images and saves the results in the ./data/augmented/<sub_directory>/<data_directory> along with the original image\n",
    "                ### print(f'Started augmenting image: {img_path}')\n",
    "                i = 0\n",
    "                for batch in datagen.flow(x, batch_size=1, save_to_dir=augmented_category_path, save_prefix=file.split(\".\")[0], save_format='jpg'):\n",
    "                    i += 1\n",
    "                    if i > 10:\n",
    "                        break ### Stop looping the generator infinitely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434ece86-f187-423d-963c-4761ae71a92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Execute the method\n",
    "\n",
    "augment_and_copy_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4c567f-1281-4b34-8359-528bca8dd007",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ‚öñÔ∏è Create a Balanced Dataset\n",
    "### This method is used to copy a certain number of images from every, train, test, and validation set.\n",
    "\n",
    "def limit_data_from_source(source_dir, dest_dir, num_images=TRAIN_DATASET_SAMPLE_COUNT):\n",
    "    if not os.path.exists(dest_dir):\n",
    "        os.makedirs(dest_dir)\n",
    "    for dataset_type in SUB_DIRECTORIES:\n",
    "        source_type_dir = os.path.join(source_dir, dataset_type)\n",
    "        dest_type_dir = os.path.join(dest_dir, dataset_type)\n",
    "        os.makedirs(dest_type_dir, exist_ok=True)\n",
    "        for category in os.listdir(source_type_dir):\n",
    "            category_path = os.path.join(source_type_dir, category)\n",
    "            if not os.path.isdir(category_path):\n",
    "                continue\n",
    "            dest_category_path = os.path.join(dest_type_dir, category)\n",
    "            os.makedirs(dest_category_path, exist_ok=True)\n",
    "\n",
    "            images = [img for img in os.listdir(category_path) if img.endswith(('jpg', 'jpeg'))]\n",
    "            print(f\"Number of images in {dataset_type}/{category_path.split('/')[-1]}: {len(images)}\")\n",
    "            ### Select the number of images provided in num_images param or the minimum number of images\n",
    "            if dataset_type == TRAIN_DIRECTORY:\n",
    "                num_images = TRAIN_DATASET_SAMPLE_COUNT\n",
    "            elif dataset_type == TEST_DIRECTORY:\n",
    "                num_images = TEST_DATASET_SAMPLE_COUNT\n",
    "            else:\n",
    "                num_images = VALIDATION_DATASET_SAMPLE_COUNT\n",
    "            selected_images = random.sample(images, min(num_images, len(images)))\n",
    "\n",
    "            for image in selected_images:\n",
    "                source_image_path = os.path.join(category_path, image)\n",
    "                dest_image_path = os.path.join(dest_category_path, image)\n",
    "                ### print(f'Copying {source_image_path} to {dest_image_path}')\n",
    "                shutil.copy(source_image_path, dest_image_path)          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9edd1c3e-d631-4f50-81e5-8cc8b108f0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_data_from_source(DATA_PATH, RNN_BALANCED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d332b1a-a13f-4b68-b2b0-af107c3e316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_images(CNN_BALANCED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1269ae-e8bf-46fb-a6e4-b5a95c228fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Since there are missing images, we need to find out exactly how many images we are missing by creating dictiionaries for each of the test, train, and val directories.\n",
    "## Function for getting missing image count for train, test, and val\n",
    "\n",
    "def get_missing_images_count(dir_name):\n",
    "    ## Create dictionaries for train, test, and validation\n",
    "    train_dict = dict()\n",
    "    test_dict = dict()\n",
    "    val_dict = dict()\n",
    "    for dataset_type in SUB_DIRECTORIES:\n",
    "        dir_type = os.path.join(dir_name, dataset_type)\n",
    "        for category in os.listdir(dir_type):\n",
    "            category_path = os.path.join(dir_type, category)\n",
    "            if not os.path.isdir(category_path):\n",
    "                continue\n",
    "            images = [img for img in os.listdir(category_path) if img.endswith(('jpg', 'jpeg'))]\n",
    "            required_count = 0\n",
    "            if dataset_type == TRAIN_DIRECTORY:\n",
    "                image_count = min(len(images), TRAIN_DATASET_SAMPLE_COUNT)\n",
    "                required_count = TRAIN_DATASET_SAMPLE_COUNT - image_count\n",
    "                train_dict[category_path.split(\"/\")[-1]] = required_count\n",
    "            elif dataset_type == TEST_DIRECTORY:\n",
    "                image_count = min(len(images), TEST_DATASET_SAMPLE_COUNT)\n",
    "                required_count = TEST_DATASET_SAMPLE_COUNT - image_count\n",
    "                test_dict[category_path.split(\"/\")[-1]] = required_count\n",
    "            else:\n",
    "                image_count = min(len(images), VALIDATION_DATASET_SAMPLE_COUNT)\n",
    "                required_count = VALIDATION_DATASET_SAMPLE_COUNT - image_count\n",
    "                val_dict[category_path.split(\"/\")[-1]] = required_count\n",
    "    return train_dict, test_dict, val_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1477246-c6ef-41f6-80c9-99d84b5c440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ‚ûï Add the Augmented Images to the Balanced Dataset to Balance the Number of Images\n",
    "\n",
    "## Get the missing number of images\n",
    "train_dict, test_dict, val_dict = get_missing_images_count(RNN_BALANCED_PATH)\n",
    "\n",
    "## Print the missing values\n",
    "\n",
    "def print_dict(dict_name, dataset_type):\n",
    "    print(f\"Missing values in {dataset_type}\")\n",
    "    print(\"----------------------------\")\n",
    "    for key, value in train_dict.items():\n",
    "        print(f\"{key} : {value}\")\n",
    "\n",
    "### print train_dict key, value pairs\n",
    "print_dict(train_dict, TRAIN_DIRECTORY)\n",
    "\n",
    "### print test_dict key, value pairs\n",
    "print_dict(test_dict, TEST_DIRECTORY)\n",
    "\n",
    "### print val_dict key, value pairs\n",
    "print_dict(val_dict, VALIDATION_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467dafbe-d8cb-4d40-9e07-0f6d96b57e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to copy the missing number of images randomly from the augmented dataset\n",
    "\n",
    "def copy_missing_images_from_augmented(src_path, dest_path):\n",
    "    # Get the missing image count\n",
    "    train_dict, test_dict, val_dict = get_missing_images_count(CNN_BALANCED_PATH)\n",
    "\n",
    "    # Dictionary mapping dataset types to their corresponding missing counts\n",
    "    missing_counts = {\n",
    "        TRAIN_DIRECTORY: train_dict,\n",
    "        TEST_DIRECTORY: test_dict,\n",
    "        VALIDATION_DIRECTORY: val_dict,\n",
    "    }\n",
    "\n",
    "    for dataset_type in SUB_DIRECTORIES:\n",
    "        src_dir_type = os.path.join(src_path, dataset_type)\n",
    "        dest_dir_type = os.path.join(dest_path, dataset_type)\n",
    "\n",
    "        # Pass the dictionary for the current dataset type\n",
    "        copy_images_for_dataset_type(src_dir_type, dest_dir_type, missing_counts[dataset_type])\n",
    "\n",
    "## Helper function to copy images for a specific dataset type\n",
    "\n",
    "def copy_images_for_dataset_type(src_dir, dest_dir, missing_dict):\n",
    "    for key, value in missing_dict.items():\n",
    "        if value == 0:\n",
    "            continue\n",
    "        src_cat_dir = os.path.join(src_dir, key)\n",
    "        dest_cat_dir = os.path.join(dest_dir, key)\n",
    "\n",
    "        # Get all available images in the source category directory\n",
    "        images = [img for img in os.listdir(src_cat_dir) if img.endswith(('jpg', 'jpeg'))]\n",
    "\n",
    "        # Randomly select the missing number of images\n",
    "        selected_images = random.sample(images, min(value, len(images)))\n",
    "\n",
    "        # Copy the selected images to the destination directory\n",
    "        for img in selected_images:\n",
    "            shutil.copy(os.path.join(src_cat_dir, img), dest_cat_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e55e0de-f822-4640-8aa6-565ac13b8564",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Copy the missing images from augmented images\n",
    "\n",
    "copy_missing_images_from_augmented(AUGMENTED_PATH, RNN_BALANCED_PATH)\n",
    "\n",
    "## Count the number of images again\n",
    "\n",
    "train_dict, test_dict, val_dict = get_missing_images_count(RNN_BALANCED_PATH)\n",
    "\n",
    "### print train_dict key, value pairs\n",
    "print_dict(train_dict, TRAIN_DIRECTORY)\n",
    "\n",
    "### print test_dict key, value pairs\n",
    "print_dict(test_dict, TEST_DIRECTORY)\n",
    "\n",
    "### print val_dict key, value pairs\n",
    "print_dict(val_dict, VALIDATION_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17f800a-b83b-4996-a42b-7b3052144309",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Image augmentation that lack the image count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb7acda-279f-4f0a-89cf-711ef9a6bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_to_df(base_path, dataset_type, sample_size):\n",
    "    path = os.path.join(base_path, dataset_path)\n",
    "    image_dir = Path(path)\n",
    "\n",
    "    file_paths = list(image_dir.glob(r'**/*.jpg'))\n",
    "    labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], file_paths))\n",
    "\n",
    "    file_paths = pd.Series(file_paths, name='Path').astype(str)\n",
    "    labels = pd.Series(labels, name='Label')\n",
    "\n",
    "    image_df = pd.concat([file_paths, labels], axis=1)\n",
    "\n",
    "    samples =[]\n",
    "    for record in image_df['Label'].unique():\n",
    "        samples.append(image_df[image_df['Label'] == record].sample(sample_size, random_state=42))\n",
    "    image_df = pd.concat(samples, axis=0).sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    return image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd29e36-64c2-45fb-9012-0271168a4b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df_train = load_images_to_df(CNN_BALANCED_PATH, TRAIN_DIRECTORY, TRAIN_DATASET_SAMPLE_COUNT)\n",
    "\n",
    "image_df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7da62c1-eca5-4b6f-919f-2caf9cd656ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show the number of images to show there are no biases in the image set\n",
    "\n",
    "pie = image_df_train['Label'].value_counts()\n",
    "pie.plot(kind='pie', autopct='%1.2f%%')\n",
    "plt.ylabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dbf80e-aefe-4513-af1d-1a78ff151a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "## üñ•Ô∏è Display Images of the Dataset\n",
    "\n",
    "### Define figure and axes\n",
    "fig, axes = plt.subplots(nrows=6, ncols=5, figsize=(15,8), subplot_kw={'xticks':[], 'yticks':[]})\n",
    "\n",
    "### Display 30 images of the dataset\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(plt.imread(image_df_train.Path[i], -1))\n",
    "    ax.set_title(image_df_train.Label[i])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6487c160-62ec-48b8-9e39-f66f10b38846",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the Test and Validation Data Frames\n",
    "\n",
    "image_df_test = load_images_to_df(CNN_BALANCED_PATH, TEST_DIRECTORY, TEST_DATASET_SAMPLE_COUNT)\n",
    "image_df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e81ad15-ffbc-4a46-bf03-4e7e2b8e338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_df_val = load_images_to_df(CNN_BALANCED_PATH, VALIDATION_DIRECTORY, VALIDATION_DATASET_SAMPLE_COUNT)\n",
    "image_df_val.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914581df-2a55-44b8-925b-7eded3a24b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(df, img_height=IMG_HEIGHT, img_width=IMG_WIDTH):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for index, row in df.iterrows():\n",
    "        img = tf.keras.utils.load_img(row['Path'], target_size=(img_height, img_width))\n",
    "        img_array = tf.keras.utils.img_to_array(img)/255.0 # Normalize\n",
    "        img_array = img_array.reshape(img_height, -1) # Flatten into rows(sequential data)\n",
    "        images.append(img_array)\n",
    "        labels.append(row['Label'])\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cdc555-d05b-4aac-a2bd-f09d493b584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_images, train_labels = preprocess_images(image_df_train)\n",
    "val_images, val_labels = preprocess_images(image_df_val)\n",
    "test_images, test_labels = preprocess_images(image_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b0f84-379f-4e4e-919c-789f0dc424c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "train_labels = label_encoder.fit_transform(train_labels)\n",
    "val_labels = label_encoder.transform(test_labels)\n",
    "test_labels = label_encoder.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4568a0e5-692e-42bf-b6e3-bc3bbde8a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoding\n",
    "train_labels = to_categorical(train_labels, NUM_CLASSES)\n",
    "val_labels = to_categorical(val_labels, NUM_CLASSES)\n",
    "test_labels = to_categorical(test_labels, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfd1436-a7a4-4d6e-9bf7-15befe76c310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # First LSTM layer with tunable number of units\n",
    "    model.add(LSTM(units=hp.Int('units_lstm_1', min_value=64, max_value=256, step=64),\n",
    "    input_shape=(IMG_HEIGHT, IMG_WIDTH *3),\n",
    "    return_sequences=True))\n",
    "\n",
    "    # Second LSTM layer with tunable number of units\n",
    "    model.add(LSTM(units=hp.Int('units_lstm_2', min_value=32, max_value=128, step=32)))\n",
    "\n",
    "    # Dropout layer with tunable rate\n",
    "    moel.add(Dropout(hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Dense layer with tunable number of units\n",
    "    model.add(Dense(units=hp.Int('units_dense', min_value=16, max_value=64, step=16), activation='relu'))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.legacy.Adam(\n",
    "            learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "        ),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1265d2ad-db57-4d95-918b-a511e124a644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tuner\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory='rnn_tuning',\n",
    "    project_name='image_classification'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d749079-5585-408b-adfb-138c7487cbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an early stopping callback\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5304632-1b7f-4cb6-945a-b9bc67105792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the hyperparameter search\n",
    "tuner.search(\n",
    "    train_images, train_labels,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    epochs=20,\n",
    "    callbacks=[stop_early],\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96fe71f-48f6-4a39-85e9-07188c1443e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters and model\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\"\"\n",
    "Best hyperparameters:\n",
    "- Units in LSTM Layer 1: {best_hps.get('units_lstm_1')}\n",
    "- Units in LSTM Layer 2: {best_hps.get('units_lstm_2')}\n",
    "- Dropout Rate: {best_hps.get('dropout_rate')}\n",
    "- Units in Dense Layer: {best_hps.get('units_dense')}\n",
    "- Learning Rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a29dc8-1f21-4cb5-a7e8-5b87d9643cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the best model and retrain\n",
    "best_model = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8a0110-2f02-41cb-9fdc-b95ac7660c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = best_model.fit(train_images, train_labels, validation_data=(val_images, val_labels),\n",
    "                    batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3a4bee-99b7-4d2f-8efd-41648e1e6259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = best_model.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {test_accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1b530d-f12e-4bdd-85e4-f19f7472467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report\n",
    "predictions = best_model.predict(test_images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = np.argmax(test_labels, axis=1)\n",
    "print(classification_report(true_classes, predicted_classes, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647a0d24-d28a-4622-8c5e-c508b311ed92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy Plot\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0704a5df-8055-49a3-bb4c-342286999f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Plot\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a209aa4-24b4-4278-b63d-1c3d5211a4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b532e82-c106-4a0d-bb18-1d137387f16f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ffef56-6b54-4a70-a4d6-df9c8e5bd10f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7042be99-c6a8-4c68-baed-87ae8bfade52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e648e1-9b86-4671-9943-902d6f1ee195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6088b29-3fbc-4888-a908-0e1ffd31667d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b77ce4-f6c1-4558-b329-7676038eca6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef08ae7-213e-4acc-a1c7-f165f3a28b98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb0a628-9709-48a0-913d-92ec26b0778f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
